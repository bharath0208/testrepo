service {
  # this is required to prevent NPE in Authenticator when running tests or locally
  validateTokenService.ml.pubkey.path = ../../service/keystore/mykey_pub.pem
  validateTokenService.icp.pubkey.path = ../../service/keystore/mykey_local.pem
  ssl {
    key-manager-factory = SunX509
    trust-manager-factory = SunX509
    context = TLS
  }
  cloudant {
      host = ${?WML_CLOUDANT_HOSTNAME}
      port = 443
      username = ${?WML_CLOUDANT_USERNAME}
      password = ${?WML_CLOUDANT_PASSWORD}
  }

  ml-repository {
    api {
      version = "${ml.repository.api.version}" # set by the maven build
      # this is the URL for the V4 API documentation
      doc-url = "https://watson-ml-v4-api.mybluemix.net/wml-restapi-cloud.html"
      # this is the request timeout for specific API endpoints
      # all end-points except POST /ml/v4/...
      # see akka.http.
      request-timeout = {
        default = 30 seconds
      }
    }
    migration {


      software-specs {

        public {

        }
        common {
          # "spark-mllib_2.3" -> "spark-mllib_2.4"
          "2e51f700-bca0-4b0d-88dc-5c6791338875" = "390d21f8-e58b-4fac-9c55-d7ceda621326"
        }
        private {
          # "ai-function_0.1-py3.6" -> "ai-function_0.2-py3.6"
          "0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda" = "435bfa8f-ddae-549a-826a-894368887231"
        }
      }

      model-types {

        public {

        }
        common {

        }
        private {

        }
      }

      runtimes {
        "ai-function_0.1-py3" = "ai-function_0.1-py3.6"
        "ai-function_0.1-py3.6" = "ai-function_0.1-py3.6"
        "caffe-ibm_1.0-py2" = "caffe-ibm_1.0-py3.6"
        "caffe-ibm_1.0-py3" = "caffe-ibm_1.0-py3.6"
        "caffe-ibm_1.0-py3.6" = "caffe-ibm_1.0-py3.6"
        "caffe2_0.8" = "caffe-ibm_1.0-py3.6"
        "caffe_1.0-ddl" = "caffe-ibm_1.0-py3.6"
        "caffe_1.0-py2" = "caffe_1.0-py3.6"
        "caffe_1.0-py3" = "caffe_1.0-py3.6"
        "caffe_1.0-py3.6" = "caffe_1.0-py3.6"
        "do_12.10" = "do_12.10"
        "do_12.9" = "do_12.9"
        "hybrid_0.1" = "hybrid_0.1"
        "hybrid_0.2" = "hybrid_0.2"
        "pmml_3.0" = "spark-mllib_2.4"
        "pmml_3.1" = "spark-mllib_2.4"
        "pmml_3.2" = "spark-mllib_2.4"
        "pmml_4.0" = "spark-mllib_2.4"
        "pmml_4.1" = "spark-mllib_2.4"
        "pmml_4.2" = "spark-mllib_2.4"
        "pmml_4.2.1" = "spark-mllib_2.4"
        "pmml_4.3" = "spark-mllib_2.4"
        "pytorch-onnx_1.0-py3" = "pytorch-onnx_1.2-py3.6"
        "pytorch-onnx_1.0-py3.6" = "pytorch-onnx_1.2-py3.6"
        "pytorch-onnx_1.1-py3.6" = "pytorch-onnx_1.1-py3.6"
        "pytorch-onnx_1.1-py3.6-edt" = "pytorch-onnx_1.1-py3.6-edt"
        "pytorch-onnx_1.2-py3.6" = "pytorch-onnx_1.2-py3.6"
        "pytorch-onnx_1.2-py3.6-edt" = "pytorch-onnx_1.2-py3.6-edt"
        "pytorch-onnx_1.3-py3.6" = "pytorch-onnx_1.3-py3.6"
        "pytorch_0.3-py2" = "pytorch-onnx_1.2-py3.6"
        "pytorch_0.3-py3" = "pytorch-onnx_1.2-py3.6"
        "pytorch_0.3-py3.6" = "pytorch-onnx_1.2-py3.6"
        "pytorch_0.4-py2" = "pytorch-onnx_1.2-py3.6"
        "pytorch_0.4-py3" = "pytorch-onnx_1.2-py3.6"
        "pytorch_0.4-py3.6" = "pytorch-onnx_1.2-py3.6"
        "pytorch_0.4-py3-horovod" = "pytorch-onnx_1.2-py3.6"
        "pytorch_1.0-py2" = "pytorch-onnx_1.2-py3.6"
        "pytorch_1.0-py3" = "pytorch-onnx_1.2-py3.6"
        "pytorch_1.0-py3.6" = "pytorch-onnx_1.2-py3.6"
        "pytorch_1.0-py3-mpi" = "pytorch-onnx_1.2-py3.6"
        "pytorch_1.0-py3.6-mpi" = "pytorch-onnx_1.2-py3.6"
        "pytorch_1.1-py3" = "pytorch-onnx_1.2-py3.6"
        "pytorch_1.1-py3.6" = "pytorch_1.1-py3.6"
        "scikit-learn_0.17-py3" = "scikit-learn_0.22-py3.6"
        "scikit-learn_0.19-py3" = "scikit-learn_0.19-py3.6"
        "scikit-learn_0.19-py3.6" = "scikit-learn_0.19-py3.6"
        "scikit-learn_0.20-py3" = "scikit-learn_0.20-py3.6"
        "scikit-learn_0.20-py3.6" = "scikit-learn_0.20-py3.6"
        "scikit-learn_0.22-py3.6" = "scikit-learn_0.22-py3.6"
        "spark-mllib_2.2" = "spark-mllib_2.4"
        "spark-mllib_2.3" = "spark-mllib_2.4"
        "spark-mllib_2.4" = "spark-mllib_2.4"
        "spss-modeler_17.1" = "spss-modeler_17.1"
        "spss-modeler_18.1" = "spss-modeler_18.1"
        "spss-modeler_18.2" = "spss-modeler_18.2"
        "tensorflow_0.11-horovod" = "tensorflow_1.15-py3.6"
        "tensorflow_1.10-py2" = "tensorflow_1.15-py3.6"
        "tensorflow_1.10-py3" = "tensorflow_1.15-py3.6"
        "tensorflow_1.11-py3" = "tensorflow_1.15-py3.6"
        "tensorflow_1.11-py3.6" = "tensorflow_1.15-py3.6"
        "tensorflow_1.13-py2" = "tensorflow_1.15-py3.6"
        "tensorflow_1.13-py3" = "tensorflow_1.15-py3.6"
        "tensorflow_1.13-py3.6" = "tensorflow_1.15-py3.6"
        "tensorflow_1.13-py3.6-ddl" = "tensorflow_1.15-py3.6"
        "tensorflow_1.13-py3.6-horovod" = "tensorflow_1.15-py3.6"
        "tensorflow_1.14-py3.6" = "tensorflow_1.15-py3.6"
        "tensorflow_1.15-py3.6" = "tensorflow_1.15-py3.6"
        "tensorflow_1.15-py3.6-ddl" = "tensorflow_1.15-py3.6-ddl"
        "tensorflow_1.15-py3.6-horovod" = "tensorflow_1.15-py3.6-horovod"
        "tensorflow_2.1-py3.6" = "tensorflow_2.1-py3.6"
        "tensorflow_1.2-py2" = "tensorflow_1.15-py3.6"
        "tensorflow_1.2-py3" = "tensorflow_1.15-py3.6"
        "tensorflow_1.3-py2" = "tensorflow_1.15-py3.6"
        "tensorflow_1.3-py2-ddl" = "tensorflow_1.15-py3.6"
        "tensorflow_1.3-py3" = "tensorflow_1.15-py3.6"
        "tensorflow_1.4-py2" = "tensorflow_1.15-py3.6"
        "tensorflow_1.4-py2-ddl" = "tensorflow_1.15-py3.6"
        "tensorflow_1.4-py3" = "tensorflow_1.15-py3.6"
        "tensorflow_1.4-py3-horovod" = "tensorflow_1.15-py3.6"
        "tensorflow_1.5-py2" = "tensorflow_1.15-py3.6"
        "tensorflow_1.5-py2-ddl" = "tensorflow_1.15-py3.6"
        "tensorflow_1.5-py3" = "tensorflow_1.15-py3.6"
        "tensorflow_1.5-py3-horovod" = "tensorflow_1.15-py3.6"
        "tensorflow_1.5-py3.6" = "tensorflow_1.15-py3.6"
        "tensorflow_1.6-py2" = "tensorflow_1.15-py3.6"
        "tensorflow_1.6-py3" = "tensorflow_1.15-py3.6"
        "tensorflow_1.7-py2" = "tensorflow_1.15-py3.6"
        "tensorflow_1.7-py3" = "tensorflow_1.15-py3.6"
        "tensorflow_1.8-py2" = "tensorflow_1.15-py3.6"
        "tensorflow_1.8-py3" = "tensorflow_1.15-py3.6"
        "tensorflow_1.9-py2" = "tensorflow_1.15-py3.6"
        "tensorflow_1.9-py3" = "tensorflow_1.15-py3.6"
        "xgboost_0.6-py3" = "xgboost_0.82-py3.6"
        "xgboost_0.80-py3" = "xgboost_0.82-py3.6"
        "xgboost_0.80-py3.6" = "xgboost_0.82-py3.6"
        "xgboost_0.82-py3" = "xgboost_0.82-py3.6"
        "xgboost_0.82-py3.6" = "xgboost_0.82-py3.6"
        "xgboost_0.90-py3.6" = "xgboost_0.90-py3.6"
        ## V3 runtimes ##
        #"torch_luajit" - not supported
        #"torch_lua52" - not supported
        #"theano_1.0" - not supported
        #"darknet_0" - not supported
        #"caffe_frcnn" - not supported
        #"pytorch_1.3-py36" - no known software_spec for pytorch_1.3*
        #"tensorflow_2.1-py36-ddl" - no known software_spec for tensorflow_2.1-py36-ddl. nearest match tensorflow_2.1-py3.6
        #"tensorflow_2.1-py36-horovod" - no known software_spec for tensorflow_2.1-py36-horovod. nearest match tensorflow_2.1-py3.6
      }
      compute {
        "lite" = "S"
        "xs" = "XS"
        "s" = "S"
        "m" = "M"
        "l" = "L"
        "xl" = "XL"
        "k80" = "K80"
        "k80x2" = "K80x2"
        "k80x4" = "K80x4"
        "v100" = "V100"
        "v100x2" = "V100x2"
        "v100x4" = "V100x4"
      }
    }
  }

  migration-job {
    memory = "1024Mi"
    cpu = 1
    image = "registry.ng.bluemix.net/wmlregistry/wmlrepositoryv4"
    secret-name = "bxwmlserv"
    maximum-jobs = 10
    create-timeout = 10 minutes
  }

  # we use FVT for now in local mode
  wml {
    host = "wml-fvt.ml.test.cloud.ibm.com"
    port = 443
    private {
      host = "private.wml-fvt.ml.test.cloud.ibm.com"
      port = 443
    }
  }
  // 1024 * 1024 * 1024 * 5 = 5GB
  upload-max-content-length = 5368709120
}

doc-root = "https://cloud.ibm.com/apidocs/machine-learning"
api {
  doc-url = ${doc-root}
}

// https://doc.akka.io/docs/akka-http/current/common/uri-model.html#query-string-in-uri
uri-parsing-mode = strict

akka {
  http {
    server {
      server-header = "WML V4 Repository ${ml.repository.api.version}" # set by the maven build
      // this is the default for all API endpoints
      // the only method that relies on this default is POST /v4/...
      request-timeout = 180 s
      // this will set the Remote-Address header
      remote-address-header = on
    }
    client.parsing.max-content-length = 1024m
  }
  // this is the default SSL configuration for FIPS compliance
  // https://github.ibm.com/NGP-TWC/ml-planning/issues/17732
  ssl-config {
    enabledProtocols = [
      "TLSv1.2"
    ]
    enabledCipherSuites = [
      "TLS_DHE_RSA_WITH_AES_128_GCM_SHA256",
      "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256",
      "TLS_DHE_RSA_WITH_AES_256_GCM_SHA384",
      "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"
    ]
  }
}

###############################################################################################
### in this (fallback) file we only define 'endpoints-dispatcher' and 'outbound-dispatcher' ###
###############################################################################################

# Used by the service for the incoming API calls
endpoints-dispatcher {
  type = Dispatcher
  executor = fork-join-executor
  fork-join-executor {
    parallelism-min = 2
    parallelism-factor = 3.0
    parallelism-max = 32
  }
}

# Used by the service for outbound calls to other services
outbound-dispatcher {
  type = Dispatcher
  executor = thread-pool-executor
  thread-pool-executor {
    fixed-pool-size = 16
  }
  throughput = 1
}
